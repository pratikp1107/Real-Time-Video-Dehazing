{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909a563a",
   "metadata": {},
   "source": [
    "# Image Dehazing using GMAN Net\n",
    "Github Link: https://github.com/sanchitvj/Image-Dehazing-using-GMAN-net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826631a",
   "metadata": {},
   "source": [
    "## Main and Defined Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "036e32d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "time: 2.36 s (started: 2022-12-15 19:16:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import random\n",
    "from PIL import Image\n",
    "import time\n",
    "import datetime\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "%load_ext autotime\n",
    "\n",
    "\n",
    "t_net = tf.keras.models.load_model(r'C:\\Users\\Pratik\\Jupyter Notebooks\\Video Deazing Project\\Github Repos\\Image-Dehazing-using-GMAN-net\\saved_model', compile = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a44a4",
   "metadata": {},
   "source": [
    "## Single Image Dehazing Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fb4e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.55 s (started: 2022-12-15 18:55:14 +05:30)\n"
     ]
    }
   ],
   "source": [
    "test_img_path = r\"E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Images\"\n",
    "\n",
    "test_img = glob.glob(test_img_path + '/*.jpg')\n",
    "# random.shuffle(test_img)\n",
    "\n",
    "for img in test_img:\n",
    "  img = Image.open(img)\n",
    "  w, h = img.size\n",
    "  img = img.resize((548, 412))\n",
    "  img = np.asarray(img) / 255.0\n",
    "  img = img.reshape((1,) + img.shape)\n",
    "\n",
    "  dehaze = t_net(img, training = False)\n",
    "\n",
    "  img = tf.reshape(dehaze,[412,548,3])\n",
    "\n",
    "  RGB_img = cv2.cvtColor(img.numpy(), cv2.COLOR_BGR2RGB)\n",
    "  RGB_img = cv2.resize(RGB_img, (w,h))\n",
    "#   print(RGB_img.shape)\n",
    "\n",
    "#   cv2.imshow('img',RGB_img)\n",
    "#   Saving the Image:\n",
    "  cv2.imwrite(r'E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Images\\Online Images\\img.png',RGB_img*255)\n",
    "\n",
    "  cv2.waitKey(0) & 0xFF == ord('q')\n",
    "  cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2e983",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c65eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_path = r'E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Images\\Online Images'\n",
    "\n",
    "# test_img = glob.glob(test_img_path + '/*.jpg')\n",
    "# random.shuffle(test_img)\n",
    "\n",
    "# for img in test_img:\n",
    "#   img = tf.io.read_file(img)\n",
    "#   img = tf.io.decode_jpeg(img, channels = 3)\n",
    "#   h, w, a = np.array(img).shape\n",
    "#   img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
    "#   img = img / 255.0\n",
    "#   img = tf.expand_dims(img, axis = 0)\n",
    "\n",
    "#   dehaze = t_net(img, training = False)\n",
    "\n",
    "#   img = tf.reshape(dehaze,[412,548,3])\n",
    "\n",
    "#   RGB_img = cv2.cvtColor(img.numpy(), cv2.COLOR_BGR2RGB)\n",
    "#   RGB_img = cv2.resize(RGB_img, (w,h))\n",
    "# #   print(RGB_img.shape)\n",
    "\n",
    "#   cv2.imshow('img',RGB_img)\n",
    "# #   Saving the Image:\n",
    "# #   cv2.imwrite(r'E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Images\\Online Images\\img.png',RGB_img)\n",
    "\n",
    "#   cv2.waitKey(0) & 0xFF == ord('q')\n",
    "#   cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81b56c",
   "metadata": {},
   "source": [
    "## Video Dehazing Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowOpLayer._defun_call at 0x000002201738CC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowOpLayer._defun_call at 0x000002200F9249D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "inputVideoPath = r\"E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Videos\\Vdo_3.mp4\"\n",
    "vidObj = cv2.VideoCapture(inputVideoPath)\n",
    "\n",
    "# Loop for frames:\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "frame_width = vidObj.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frame_height = vidObj.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = vidObj.get(cv2.CAP_PROP_FPS)\n",
    "frame_nos = vidObj.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "# save = cv2.VideoWriter(r'E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Videos\\output_small.mp4',fourcc, fps, (640, 480))\n",
    "save = cv2.VideoWriter(r'E:\\College Education\\DA-IICT\\Study\\Sem 3\\Pratik - Projects\\Video Dehazing\\Input Images & Videos\\Input Videos\\output_small3.mp4',fourcc, fps, (int(frame_width), int(frame_height)))\n",
    "\n",
    "###\n",
    "for frame_idx in range(int(frame_nos+1)):\n",
    "  ret, I = vidObj.read()\n",
    "\n",
    "  if ret:\n",
    "    I = cv2.resize(I, (548, 412))\n",
    "    x = I / 255.0\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    dehaze = t_net(x, training = False)\n",
    "\n",
    "    x = tf.reshape(dehaze,[412,548,3])\n",
    "    x = cv2.cvtColor(x.numpy(), cv2.COLOR_BGR2RGB)\n",
    "    x = x * 255\n",
    "    x = (np.rint(x)).astype(np.uint8)\n",
    "    x = cv2.resize(x, (int(frame_width), int(frame_height)))\n",
    "    save.write(x)\n",
    "    \n",
    "  # Breaking Loop:\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "vidObj.release()\n",
    "save.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('Execution Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e66eb",
   "metadata": {},
   "source": [
    "## Real-Time Dehazing Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a734fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowOpLayer._defun_call at 0x000001CB9240C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowOpLayer._defun_call at 0x000001CBFFCBD160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    vidObj_vs = VideoStream(0).start()\n",
    "    \n",
    "    time.sleep(1.0)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Defining FPS:\n",
    "    FPS_Start_Time = 0\n",
    "    FPS = 0\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        I = vidObj_vs.read()\n",
    "        # FPS:\n",
    "        h, w, a = I.shape\n",
    "        FPS_End_Time = time.time()\n",
    "        FPS = 1/(FPS_End_Time - FPS_Start_Time)\n",
    "        FPS_Start_Time = FPS_End_Time\n",
    "        FPS_Text = \"FPS: {:.2f}\".format(FPS)\n",
    "        cv2.putText(I, FPS_Text, (5,20), cv2.FONT_HERSHEY_COMPLEX, 0.7, (0,0,0), 1)\n",
    "        \n",
    "        cv2.imshow('Input Sequence',I)\n",
    "        \n",
    "        I = cv2.resize(I, (548, 412))\n",
    "        x = I / 255.0\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "        \n",
    "        dehaze = t_net(x, training = False)\n",
    "        \n",
    "        x = tf.reshape(dehaze,[412,548,3])\n",
    "#         x = cv2.cvtColor(x.numpy(), cv2.COLOR_BGR2RGB)\n",
    "        x = x * 255\n",
    "        x = (np.rint(x)).astype(np.uint8)\n",
    "        x = cv2.resize(x, (w,h))\n",
    "        cv2.imshow('Output Sequence',x)\n",
    "\n",
    "        # Breaking Loop:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    vidObj_vs.stream.release()\n",
    "    # save.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
